{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import string\n",
    "pd.options.display.float_format = '${:16,.0f}'.format\n",
    "\n",
    "df = pd.read_excel('../misc_analytics/compiled_sl_mm.xlsx')\n",
    "df = df.fillna(method='pad')\n",
    "df2 = pd.DataFrame(columns=df.columns)\n",
    "df.loc[:25]\n",
    "df3 = pd.concat([df2, df])\n",
    "total_rows = len(df3.index)\n",
    "for i in range(0, total_rows, 10):\n",
    "    j = i + 10\n",
    "    df_final = df3[i:j]\n",
    "    writer = pd.ExcelWriter('../misc_analytics/compiled_sl_mm_cleaned'+str(i)+'.xlsx', engine='xlsxwriter')\n",
    "    df_final.to_excel(writer, sheet_name='master')\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-ca34ed06ba58>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-ca34ed06ba58>\"\u001b[1;36m, line \u001b[1;32m29\u001b[0m\n\u001b[1;33m    not_like_customers = ['nirmal', 'acclaris', 'cintas', 'clarisity', 'tokyo', 'tokiy',,'LAMBDATEK', 'LINTAS', 'SHASUN','MUDRA ELECTRONICS', 'NEHA ELE','REDIFFCOM']\u001b[0m\n\u001b[1;37m                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from IPython.display import display, HTML\n",
    "import string\n",
    "import re\n",
    "pd.options.display.float_format = '${:16,.0f}'.format\n",
    "\n",
    "skip_rec = 10\n",
    "\n",
    "engine_url = 'mysql://root:Jey03$78@localhost/mysourcedata?charset=utf8'\n",
    "engine = create_engine(engine_url, pool_size=100, pool_recycle=3600, echo_pool=True)\n",
    "conn = engine.connect()\n",
    "\n",
    "#like_customers = ['dell','first advan','firstadvan','CSC','serco','mphasis','m-phasis','persistent','sutherlan','suther lan']\n",
    "df_prem = pd.read_excel('../misc_analytics/guj_geo.xlsx')\n",
    "df_prem = df_prem.fillna(method='pad')\n",
    "total_recs = len(df_prem.index)\n",
    "df_master = pd.DataFrame(columns=df_prem.columns)\n",
    "\n",
    "\n",
    "for i in range(0, total_recs, skip_rec):\n",
    "    j = i + skip_rec\n",
    "    print 'Processing ' + str(i) + ' to ' + str(j) + '/' + str(total_recs) + '...'\n",
    "    df_temp = df_prem[i:j]\n",
    "    like_customers = df_temp['like_names']\n",
    "    not_like_customers = ['nirmal', 'acclaris', 'cintas', 'clarisity', 'tokyo', 'tokiy','tokio','LAMBDATEK', 'LINTAS', 'SHASUN','MUDRA ELECTRONICS', 'NEHA ELE','REDIFFCOM']\n",
    "    first_time = 1\n",
    "    or_conditions = []\n",
    "    and_conditions = []\n",
    "    for name in like_customers:\n",
    "        if first_time == 1:\n",
    "            or_conditions.append('customer_name LIKE ' + '\"%%' + name + '%%\"')\n",
    "        else:\n",
    "            or_conditions.append(' OR customer_name LIKE ' + '\"%%' + name + '%%\"')\n",
    "        first_time += 1\n",
    "\n",
    "    first_time = 1\n",
    "    for name in not_like_customers:\n",
    "        if first_time == 1:\n",
    "            and_conditions.append('customer_name NOT LIKE ' + '\"%%' + name + '%%\"')\n",
    "        else:\n",
    "            and_conditions.append(' AND customer_name NOT LIKE ' + '\"%%' + name + '%%\"')\n",
    "        first_time += 1\n",
    "\n",
    "    conditions = []\n",
    "    conditions.append('SELECT * FROM ent_dump_from_finance WHERE')\n",
    "    if len(not_like_customers) > 0:\n",
    "        conditions.append('(')\n",
    "    conditions.append(''.join(or_conditions))\n",
    "    if len(not_like_customers) > 0:\n",
    "        conditions.append(') AND ')\n",
    "        conditions.append(''.join(and_conditions))\n",
    "    sql_query = \" \".join(conditions)\n",
    "    #print sql_query\n",
    "    df = pd.read_sql_query(sql_query, engine)\n",
    "    df.rename(columns=string.lower, inplace=True)\n",
    "\n",
    "    #updatable_fields = ['mapped_name', 'file_name', 'sheet_name']\n",
    "    for index, row in df_temp.iterrows():\n",
    "        #updatable_data = [row['unique_name'],row['file_name'],row['sheet_name']]\n",
    "        #df.ix[df.customer_name.str.contains(row['like_names'], case=False).fillna(False), updatable_fields] = updatable_data\n",
    "        df.ix[df.customer_name.str.contains(row['like_names'], case=False).fillna(False), 'mapped_name'] = row['unique_name']\n",
    "        df.ix[df.customer_name.str.contains(row['like_names'], case=False).fillna(False), 'file_name'] = row['file_name']\n",
    "        df.ix[df.customer_name.str.contains(row['like_names'], case=False).fillna(False), 'sheet_name'] = row['sheet_name']\n",
    "\n",
    "    df['year'] = df['fiscal_quarter_id'].map(lambda x: int(x[:4]))\n",
    "    df_master = pd.concat([df_master, df])\n",
    "    print 'Processed ' + str(i) + ' to ' + str(j) + '/' + str(total_recs) + '!'\n",
    "writer = pd.ExcelWriter('../misc_analytics/bookings_history.xlsx', engine='xlsxwriter')\n",
    "print 'Dropping Unnecessary Columns...'\n",
    "df_master.drop(['tms_sales_allocated_bookings_quantity', 'corp_arch', 'coll', 'dc', 'bn', 'ipngn', 'small', 'mobility_net', 'vch_net','others','vertical','tms_sales_allocated_bookings_standard_cost','prod_ser','standard_cost','tms_sales_allocated_bookings_base_list'], inplace=True, axis=1)\n",
    "print 'Unnecessary Columns dropped!'\n",
    "print 'Writing in Excel....'\n",
    "df_master.to_excel(writer, sheet_name='historical')\n",
    "writer.save()\n",
    "print 'End of Process!'\n",
    "display(df.groupby(['mapped_name', 'year'])['booking_net'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 to 10/10...\n",
      "SELECT * FROM ent_dump_from_finance WHERE ( customer_name LIKE \"%%first advan%%\" OR customer_name LIKE \"%%firstadvan%%\" OR customer_name LIKE \"%%CSC%%\" OR customer_name LIKE \"%%serco%%\" OR customer_name LIKE \"%%mphasis%%\" OR customer_name LIKE \"%%m-phasis%%\" OR customer_name LIKE \"%%m - phasis%%\" OR customer_name LIKE \"%%persistent%%\" OR customer_name LIKE \"%%sutherlan%%\" OR customer_name LIKE \"%%suther lan%%\" ) AND  customer_name NOT LIKE \"%%HCSC%%\"\n",
      "Processed 0 to 10/10!\n",
      "Dropping Unnecessary Columns...\n",
      "Unnecessary Columns dropped!\n",
      "Writing in Excel....\n",
      "End of Process!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mapped_name      year\n",
       "CSC              2013   $         431,167\n",
       "                 2014   $        -154,751\n",
       "                 2015   $       1,529,095\n",
       "                 2016   $         463,793\n",
       "First advantage  2013   $         499,822\n",
       "                 2014   $         973,529\n",
       "                 2015   $         268,351\n",
       "                 2016   $          22,796\n",
       "Mphasis          2013   $         864,302\n",
       "                 2014   $       1,076,418\n",
       "                 2015   $         381,127\n",
       "                 2016   $         787,713\n",
       "Persistant       2013   $         450,238\n",
       "                 2014   $       1,253,612\n",
       "                 2015   $       1,747,296\n",
       "                 2016   $       1,418,017\n",
       "Serco            2013   $         432,697\n",
       "                 2014   $         483,762\n",
       "                 2015   $         998,278\n",
       "                 2016   $       1,240,799\n",
       "sutherland       2013   $         794,960\n",
       "                 2014   $       1,486,157\n",
       "                 2015   $       1,179,563\n",
       "                 2016   $       1,252,661\n",
       "Name: booking_net, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from IPython.display import display, HTML\n",
    "import string\n",
    "import re\n",
    "pd.options.display.float_format = '${:16,.0f}'.format\n",
    "\n",
    "skip_rec = 10\n",
    "\n",
    "engine_url = 'mysql://root:Jey03$78@localhost/mysourcedata?charset=utf8'\n",
    "engine = create_engine(engine_url, pool_size=100, pool_recycle=3600, echo_pool=True)\n",
    "conn = engine.connect()\n",
    "\n",
    "#like_customers = ['dell','first advan','firstadvan','CSC','serco','mphasis','m-phasis','persistent','sutherlan','suther lan']\n",
    "df_prem = pd.read_excel('../misc_analytics/prem_list_accounts.xlsx')\n",
    "df_prem = df_prem.fillna(method='pad')\n",
    "total_recs = len(df_prem.index)\n",
    "df_master = pd.DataFrame(columns=df_prem.columns)\n",
    "\n",
    "\n",
    "for i in range(0, total_recs, skip_rec):\n",
    "    j = i + skip_rec\n",
    "    print 'Processing ' + str(i) + ' to ' + str(j) + '/' + str(total_recs) + '...'\n",
    "    df_temp = df_prem[i:j]\n",
    "    like_customers = df_temp['like_names']\n",
    "    not_like_customers = ['HCSC']\n",
    "    first_time = 1\n",
    "    or_conditions = []\n",
    "    and_conditions = []\n",
    "    for name in like_customers:\n",
    "        if first_time == 1:\n",
    "            or_conditions.append('customer_name LIKE ' + '\"%%' + name + '%%\"')\n",
    "        else:\n",
    "            or_conditions.append(' OR customer_name LIKE ' + '\"%%' + name + '%%\"')\n",
    "        first_time += 1\n",
    "\n",
    "    first_time = 1\n",
    "    for name in not_like_customers:\n",
    "        if first_time == 1:\n",
    "            and_conditions.append('customer_name NOT LIKE ' + '\"%%' + name + '%%\"')\n",
    "        else:\n",
    "            and_conditions.append(' OR customer_name NOT LIKE ' + '\"%%' + name + '%%\"')\n",
    "        first_time += 1\n",
    "\n",
    "    conditions = []\n",
    "    conditions.append('SELECT * FROM ent_dump_from_finance WHERE')\n",
    "    if len(not_like_customers) > 0:\n",
    "        conditions.append('(')\n",
    "    conditions.append(''.join(or_conditions))\n",
    "    if len(not_like_customers) > 0:\n",
    "        conditions.append(') AND ')\n",
    "        conditions.append(''.join(and_conditions))\n",
    "    sql_query = \" \".join(conditions)\n",
    "    print sql_query\n",
    "    df = pd.read_sql_query(sql_query, engine)\n",
    "    df.rename(columns=string.lower, inplace=True)\n",
    "\n",
    "    #updatable_fields = ['mapped_name', 'file_name', 'sheet_name']\n",
    "    for index, row in df_temp.iterrows():\n",
    "        #updatable_data = [row['unique_name'],row['file_name'],row['sheet_name']]\n",
    "        #df.ix[df.customer_name.str.contains(row['like_names'], case=False).fillna(False), updatable_fields] = updatable_data\n",
    "        df.ix[df.customer_name.str.contains(row['like_names'], case=False).fillna(False), 'mapped_name'] = row['unique_name']\n",
    "        df.ix[df.customer_name.str.contains(row['like_names'], case=False).fillna(False), 'file_name'] = row['file_name']\n",
    "        df.ix[df.customer_name.str.contains(row['like_names'], case=False).fillna(False), 'sheet_name'] = row['sheet_name']\n",
    "\n",
    "    df['year'] = df['fiscal_quarter_id'].map(lambda x: int(x[:4]))\n",
    "    df_master = pd.concat([df_master, df])\n",
    "    print 'Processed ' + str(i) + ' to ' + str(j) + '/' + str(total_recs) + '!'\n",
    "writer = pd.ExcelWriter('../misc_analytics/bookings_history_prem.xlsx', engine='xlsxwriter')\n",
    "print 'Dropping Unnecessary Columns...'\n",
    "df_master.drop(['tms_sales_allocated_bookings_quantity', 'corp_arch', 'coll', 'dc', 'bn', 'ipngn', 'small', 'mobility_net', 'vch_net','others','vertical','tms_sales_allocated_bookings_standard_cost','prod_ser','standard_cost','tms_sales_allocated_bookings_base_list'], inplace=True, axis=1)\n",
    "print 'Unnecessary Columns dropped!'\n",
    "print 'Writing in Excel....'\n",
    "df_master.to_excel(writer, sheet_name='historical')\n",
    "writer.save()\n",
    "print 'End of Process!'\n",
    "display(df.groupby(['mapped_name', 'year'])['booking_net'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from IPython.display import display, HTML\n",
    "import string\n",
    "import re\n",
    "pd.options.display.float_format = '${:10,.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Account Assignment\n",
    "def get_wb():\n",
    "    wd_path = '../account_assignment/'\n",
    "    wb_file = wd_path + 'FY17_WB_v1.xlsx'\n",
    "    xl_wb = pd.ExcelFile(wb_file)\n",
    "    df1 = xl_wb.parse('FY17 ACCOUNTS')\n",
    "    df1.rename(columns=string.lower, inplace=True)\n",
    "    fill_na = lambda x: np.nan\n",
    "    df1['fy17 owner userid '] = df1['fy17 owner userid '].map(fill_na)\n",
    "    df1['fy17 team agent name (for team agents only)'] = df1['fy17 team agent name (for team agents only)'].map(fill_na)\n",
    "    df1['fy17 owner sl6 node'] = df1['fy17 owner sl6 node'].map(fill_na)\n",
    "    xl_wb = pd.ExcelFile(wb_file)\n",
    "    df2 = xl_wb.parse('NEW ACCOUNTS')\n",
    "    df2.rename(columns=string.lower, inplace=True)\n",
    "    return (df1, df2)\n",
    "def get_rows_cols(df):\n",
    "    return (len(df.index), len(df.columns))\n",
    "def print_dim(rows, cols, comment=''):\n",
    "    print comment + \"Row(s): %d | Column(s): %d\" % (rows, cols)\n",
    "def read_get_wb_update(file_name):\n",
    "    wd_path = '../account_assignment/'\n",
    "    wb_file = wd_path + file_name\n",
    "    xl_wb = pd.ExcelFile(wb_file)\n",
    "    df1= xl_wb.parse('existing')\n",
    "    df1.rename(columns=string.lower, inplace=True)\n",
    "    df2= xl_wb.parse('NEW ACCOUNTS')\n",
    "    df2.rename(columns=string.lower, inplace=True)\n",
    "    return (df1, df2)\n",
    "def compile_data(file_name, existing_cols, new_cols):\n",
    "    # Prasad Kulkarni (prakulk2) <prakulk2@cisco.com>/Fri 6/24/2016 8:55 PM/FW: Accounts workbook for COMM FY17/Prakulk2 - SELECT ACCOUNT LIST -  FY17_WB_v1.xlsx\n",
    "    # And df with prefix 'e' stands for existing, with prefix 'n' stands for new\n",
    "    existing_cols = existing_cols.append(pd.Series(['updated_file_name']))\n",
    "    new_cols = new_cols.append(pd.Series(['updated_file_name']))\n",
    "    df_input = pd.read_excel('../account_assignment/'+file_name+'.xlsx')\n",
    "    df_comp_existing = pd.DataFrame(columns=existing_cols)\n",
    "    df_comp_new = pd.DataFrame(columns=new_cols)\n",
    "    df_log = pd.DataFrame(columns=['file_name', 'description', 'existing_rows', 'existing_cols', 'new_rows', 'new_cols'])\n",
    "    for index, input_data in df_input.iterrows():\n",
    "        print 'Processing File %s...' % (input_data.file_name)\n",
    "        #file_name = 'Prakulk2 - SELECT ACCOUNT LIST -  FY17_WB_v1.xlsx'\n",
    "        (edf, ndf) = read_get_wb_update(input_data.file_name+'.xlsx')\n",
    "        edf['updated_file_name'] = input_data.file_name\n",
    "        ndf['updated_file_name'] = input_data.file_name\n",
    "        (e_rows, e_cols) = get_rows_cols(edf)\n",
    "        (n_rows, n_cols) = get_rows_cols(ndf)\n",
    "        print_dim(e_rows, e_cols, comment='Existing Accounts=> ')\n",
    "        print_dim(n_rows, n_cols, comment='New Accounts=> ')\n",
    "        log_dict = {\n",
    "            'file_name': [input_data.file_name],\n",
    "            'description': [input_data.description],\n",
    "            'existing_rows': [e_rows],\n",
    "            'existing_cols': [e_cols],\n",
    "            'new_rows': [n_rows],\n",
    "            'new_cols': [n_cols]\n",
    "        }\n",
    "        df_comp_existing = pd.concat([df_comp_existing, edf])\n",
    "        df_comp_new = pd.concat([df_comp_new, ndf])\n",
    "        df_log = pd.concat([df_log, DataFrame.from_dict(log_dict)])\n",
    "        print \"Writing Individual data in Excel...\"\n",
    "        writer = pd.ExcelWriter('../account_assignment/compiled_'+input_data.file_name+'.xlsx', engine='xlsxwriter')\n",
    "        edf.to_excel(writer, sheet_name='FY17 ACCOUNTS', columns=existing_cols)\n",
    "        ndf.to_excel(writer, sheet_name='NEW ACCOUNTS', columns=new_cols)\n",
    "        DataFrame.from_dict(log_dict).to_excel(writer, sheet_name='LOG')\n",
    "        writer.save()\n",
    "        print \"Individual data has been written in Excel!\"\n",
    "        print 'End of Processing File %s!' % (input_data.file_name)\n",
    "    print \"Writing compiled data in Excel...\"\n",
    "    writer = pd.ExcelWriter('../account_assignment/assignment_fy17_accounts.xlsx', engine='xlsxwriter')\n",
    "    df_comp_existing.to_excel(writer, sheet_name='FY17 ACCOUNTS', columns=existing_cols)\n",
    "    df_comp_new.to_excel(writer, sheet_name='NEW ACCOUNTS', columns=new_cols)\n",
    "    df_log.to_excel(writer, sheet_name='LOG')\n",
    "    writer.save()\n",
    "    print \"Compiled data has been written in Excel!\"\n",
    "    print 'End of Compilation!'\n",
    "    return (df_comp_existing, df_comp_new, df_log)\n",
    "\n",
    "def validate_wb(df1, df2, df_comp_existing, df_comp_new):\n",
    "    df1.loc[df1['row'].isin(df_comp_existing['row']), ['fy17 owner userid ', 'fy17 team agent name (for team agents only)', 'fy17 owner sl6 node']] = df_comp_existing[['fy17 owner userid ', 'fy17 team agent name (for team agents only)', 'fy17 owner sl6 node']]\n",
    "    print \"Writing validated data in Excel...\"\n",
    "    writer = pd.ExcelWriter('../account_assignment/assignment_fy17_accounts_validated.xlsx', engine='xlsxwriter')\n",
    "    df1.to_excel(writer, sheet_name='FY17 ACCOUNTS', columns=existing_cols)\n",
    "    df2.to_excel(writer, sheet_name='NEW ACCOUNTS', columns=new_cols)\n",
    "    writer.save()\n",
    "    print \"Validated data has been written in Excel!\"\n",
    "    \n",
    "def validate_wb2(df1, df2, df_comp_existing, df_comp_new):\n",
    "    existing_cols = df1.columns\n",
    "    new_cols = df2.columns\n",
    "    existing_cols = existing_cols.append(pd.Series(['updated_file_name']))\n",
    "    new_cols = new_cols.append(pd.Series(['updated_file_name']))\n",
    "    print 'Mapping is going on...'\n",
    "    for index, rows in df_comp_existing.iterrows():\n",
    "        df1.ix[df1['row']==rows['row'], 'account type'] = rows['account type']\n",
    "        df1.ix[df1['row']==rows['row'], 'fy17 owner userid '] = rows['fy17 owner userid ']\n",
    "        df1.ix[df1['row']==rows['row'], 'fy17 team agent name (for team agents only)'] = rows['fy17 team agent name (for team agents only)']\n",
    "        df1.ix[df1['row']==rows['row'], 'fy17 owner sl6 node'] = rows['fy17 owner sl6 node']\n",
    "        df1.ix[df1['row']==rows['row'], 'updated_file_name'] = rows['updated_file_name']\n",
    "    df2 = pd.concat([df2, df_comp_new])\n",
    "    #df1.loc[df1['row'].isin(df_comp_existing['row']), ['fy17 owner userid ', 'fy17 team agent name (for team agents only)', 'fy17 owner sl6 node']] = df_comp_existing[['fy17 owner userid ', 'fy17 team agent name (for team agents only)', 'fy17 owner sl6 node']]\n",
    "    print 'Mapping is complete!'\n",
    "    print \"Writing validated data in Excel...\"\n",
    "    writer = pd.ExcelWriter('../account_assignment/assignment_fy17_accounts_validated.xlsx', engine='xlsxwriter')\n",
    "    df1.to_excel(writer, sheet_name='FY17 ACCOUNTS', columns=existing_cols)\n",
    "    df2.to_excel(writer, sheet_name='NEW ACCOUNTS', columns=new_cols)\n",
    "    writer.save()\n",
    "    print \"Validated data has been written in Excel!\"\n",
    "\n",
    "def get_overlapped_file_names(row_no, df_full_dup):\n",
    "    temp_array = []\n",
    "    for index, rows in df_full_dup.iterrows():\n",
    "        if row_no == rows['row']:\n",
    "            temp_array.append(rows['updated_file_name'])\n",
    "    return \"/\".join(temp_array)\n",
    "\n",
    "def get_overlapped_user_ids(row_no, df_full_dup):\n",
    "    temp_array = []\n",
    "    for index, rows in df_full_dup.iterrows():\n",
    "        if row_no == rows['row']:\n",
    "            temp_array.append(rows['fy17 owner userid '])\n",
    "    return \"/\".join(temp_array)\n",
    "\n",
    "\n",
    "def revalidate_by_overlap():\n",
    "    xl = pd.ExcelFile('../account_assignment/assignment_fy17_accounts_validated.xlsx')\n",
    "    df1 = xl.parse('FY17 ACCOUNTS')\n",
    "    df2 = xl.parse('NEW ACCOUNTS')\n",
    "    cols_rqrd1 = df1.columns\n",
    "    cols_rqrd2 = df2.columns\n",
    "    xl = pd.ExcelFile('../account_assignment/assignment_overlapping.xlsx')\n",
    "    df_dup = xl.parse('overlap')\n",
    "    print 'Re-validation on progress...'\n",
    "    for index, rows in df_dup.iterrows():\n",
    "        df1.ix[df1['row']==rows['row'], 'account type'] = np.nan\n",
    "        df1.ix[df1['row']==rows['row'], 'fy17 owner userid '] = np.nan\n",
    "        df1.ix[df1['row']==rows['row'], 'fy17 team agent name (for team agents only)'] = np.nan\n",
    "        df1.ix[df1['row']==rows['row'], 'fy17 owner sl6 node'] = np.nan\n",
    "        df1.ix[df1['row']==rows['row'], 'updated_file_name'] = np.nan\n",
    "    print 'Re-validation completed!'\n",
    "    print \"Writing Re-validated data in Excel...\"\n",
    "    writer = pd.ExcelWriter('../account_assignment/assignment_fy17_accounts_re_validated.xlsx', engine='xlsxwriter')\n",
    "    df1.to_excel(writer, sheet_name='FY17 ACCOUNTS', columns=cols_rqrd1)\n",
    "    df2.to_excel(writer, sheet_name='NEW ACCOUNTS', columns=cols_rqrd2)\n",
    "    writer.save()\n",
    "    print \"Re-validated data has been written in Excel!\"\n",
    " \n",
    "   \n",
    "def write_overlap_in_excel():\n",
    "    print 'Checking for overlapping....'\n",
    "    xl = pd.ExcelFile('../account_assignment/assignment_fy17_accounts.xlsx')\n",
    "    df = xl.parse('FY17 ACCOUNTS')\n",
    "    cols_rqrd = df.columns\n",
    "    cols_rqrd = cols_rqrd.append(pd.Series(['overlap_user_ids']))\n",
    "    df_full_dup_rem = df.drop_duplicates(['row'], keep=False)\n",
    "    df_half_dup_rem = df.drop_duplicates(['row'])\n",
    "    total = len(df.index)\n",
    "    no_dup_full = len(df_full_dup_rem.index)\n",
    "    no_dup_half = len(df_half_dup_rem.index)\n",
    "\n",
    "    df_full_dup = df[-df.row.isin(df_full_dup_rem.row)]\n",
    "    df_half_dup = df_full_dup.drop_duplicates(['row'], keep='first')\n",
    "    if len(df_full_dup.index) != 0:\n",
    "        df_half_dup.updated_file_name = df_half_dup['row'].map(lambda x: get_overlapped_file_names(x, df_full_dup))\n",
    "        df_half_dup['overlap_user_ids'] = df_half_dup['row'].map(lambda x: get_overlapped_user_ids(x, df_full_dup))\n",
    "\n",
    "        print \"Writing Overlapping data in Excel...\"\n",
    "        writer = pd.ExcelWriter('../account_assignment/assignment_overlapping.xlsx', engine='xlsxwriter')\n",
    "        df_full_dup.to_excel(writer, sheet_name='full_overlap', columns=df.columns)\n",
    "        df_half_dup.to_excel(writer, sheet_name='overlap', columns=cols_rqrd)\n",
    "        writer.save()\n",
    "        print \"Overlapping data has been written in Excel!\"\n",
    "    else:\n",
    "        print \"No Duplicates Found!\"\n",
    "    print \"Total Row(s): %d\" % (total)\n",
    "    print \"Non Duplicated Row(s): %d (ful) | %d (half)\" % (no_dup_full, no_dup_half)\n",
    "    print \"Remaining w.r.t Full Duplicates Row(s): %d\" % (len(df_full_dup.index))\n",
    "    print \"Remaining w.r.t Half Duplicates Row(s): %d\" % (len(df_half_dup.index))\n",
    "    print 'Overlapping information has been written in Excel!'\n",
    "\n",
    "    \n",
    "    \n",
    "#(df1, df2) = get_wb()\n",
    "#print df1.columns\n",
    "#(df_comp_existing, df_comp_new, df_log) = compile_data('compile_engine_input', df1.columns, df2.columns)\n",
    "#validate_wb2(df1, df2, df_comp_existing, df_comp_new)\n",
    "#write_overlap_in_excel()\n",
    "#revalidate_by_overlap()\n",
    "#print df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_input_revalidation():\n",
    "    df_input = pd.read_excel('../account_assignment/validate_engine_input.xlsx')\n",
    "    df_input = df_input[df_input.is_complete == 'No']\n",
    "    df_inp_olap = df_input[(df_input.overlapping == 'Yes') & (df_input.revision == 'No')]\n",
    "    df_inp_rev = df_input[(df_input.revision == 'Yes') & (df_input.overlapping == 'No')]\n",
    "    return (df_inp_olap, df_inp_rev)\n",
    "def get_versions(file_name, comment):\n",
    "        xl = pd.ExcelFile('../account_assignment/'+file_name+'.xlsx')\n",
    "        df_exist = xl.parse('existing')\n",
    "        df_exist.rename(columns=string.lower, inplace=True)\n",
    "        df_exist['file_version'] = comment\n",
    "        df_newac = xl.parse('NEW ACCOUNTS')\n",
    "        df_newac.rename(columns=string.lower, inplace=True)\n",
    "        df_newac['file_version'] = comment\n",
    "        return (df_exist, df_newac)\n",
    "def get_wb():\n",
    "    wd_path = '../account_assignment/'\n",
    "    wb_file = wd_path + 'FY17_WB_v1_mapped.xlsx'\n",
    "    xl_wb = pd.ExcelFile(wb_file)\n",
    "    df1 = xl_wb.parse('FY17 ACCOUNTS')\n",
    "    df1.rename(columns=string.lower, inplace=True)\n",
    "    df2 = xl_wb.parse('NEW ACCOUNTS')\n",
    "    df2.rename(columns=string.lower, inplace=True)\n",
    "    return (df1, df2)\n",
    "\n",
    "def get_overlapping():\n",
    "    wd_path = '../account_assignment/'\n",
    "    wb_file = wd_path + 'assignment_overlapping.xlsx'\n",
    "    xl_wb = pd.ExcelFile(wb_file)\n",
    "    df = xl_wb.parse('overlap')\n",
    "    df.rename(columns=string.lower, inplace=True)\n",
    "    return df\n",
    "\n",
    "def write_wb(df1_1, df2_1, cols_rqrd1, cols_rqrd2, version):\n",
    "    print \"size of df1_1 is: %d\" % (len(df1_1.index))\n",
    "    print \"Writing Re-validated data in Excel...\"\n",
    "    writer = pd.ExcelWriter('../account_assignment/assignment_fy17_accounts_re_validated_v'+str(version)+'.xlsx', engine='xlsxwriter')\n",
    "    df1_1.to_excel(writer, sheet_name='FY17 ACCOUNTS', columns=cols_rqrd1)\n",
    "    df2_1.to_excel(writer, sheet_name='NEW ACCOUNTS', columns=cols_rqrd2)\n",
    "    writer.save()\n",
    "    print \"Re-validated data has been written in Excel!\"\n",
    "\n",
    "def validate_write_revision():\n",
    "    print \"Reading Inputs for the Revision Files...\"\n",
    "    (df_inp_olap, df_inp_rev) = get_input_revalidation()\n",
    "    (df1, df2) = get_wb()\n",
    "    cols_rqrd1 = df1.columns\n",
    "    #print cols_rqrd1\n",
    "    #cols_rqrd1 = cols_rqrd1.append(pd.Series(['updated_file_name','overlap_user_ids','overlap_update_info','remarks']))\n",
    "    cols_rqrd2 = df2.columns\n",
    "    df1_1 = pd.DataFrame(columns=cols_rqrd1)\n",
    "    df2_1 = pd.DataFrame(columns=cols_rqrd2)\n",
    "    print \"Revision Files' details are in dataframe now!\"\n",
    "    print \"Reading Revision Files & Validating...\"\n",
    "    for index, rows in df_inp_rev.iterrows():\n",
    "        (df_old_exist, df_old_newac) = get_versions(rows.file_name_old, 'old')\n",
    "        (df_new_exist, df_new_newac) = get_versions(rows.file_name_new, 'new')\n",
    "        df_exist = pd.concat([df_old_exist, df_new_exist])\n",
    "        df_newac = pd.concat([df_old_newac, df_new_newac])\n",
    "        df_exist = df_exist.drop_duplicates(['row'], keep='last')\n",
    "        df_newac = df_newac.drop_duplicates(['account name'], keep='last')\n",
    "        df1 = pd.concat([df1, df_exist])\n",
    "        df2 = pd.concat([df2, df_newac])\n",
    "        df1 = df1.drop_duplicates(['row'], keep='last')\n",
    "        #df2 = df2.drop_duplicates(['account name'], keep='last')\n",
    "        df1_1 = pd.concat([df1_1, df1])\n",
    "        df2_1 = pd.concat([df2_1, df2])\n",
    "    print \"Completed reading validating Revision Files!\"\n",
    "    print \"Reading Overlapping Files & validating...\"\n",
    "    print \"size of df1_1 is: %d\" % (len(df1_1.index))\n",
    "    for index, rows in df_inp_olap.iterrows():\n",
    "        df_overlap = get_overlapping()\n",
    "        df1_1 = pd.concat([df1_1, df_overlap])\n",
    "        df1_1 = df1_1.drop_duplicates(['row'], keep='last')\n",
    "    print \"Completed reading & validating Overlapping Files!\"\n",
    "    print \"size of df1_1 is: %d\" % (len(df1_1.index))\n",
    "    #New Accounts Addition in Rajeev's file\n",
    "    print \"Reading Rajeev's new Addition...\"\n",
    "    (df_rajeev_exist, df_rajeev_newac) = get_versions('Rajeev_FY17_WB_v1_SOUTH', 'new')\n",
    "    df_rajeev_newac['updated_file_name'] = 'Rajeev_FY17_WB_v1_SOUTH'\n",
    "    df2_1 = pd.concat([df2_1, df_rajeev_newac])\n",
    "    print \"Completed reading Rajeev's new Addition!\"\n",
    "    df1_1.ix[df1_1['account type'].str.contains('select', case=False).fillna(False),'account type'] = 'Named'\n",
    "    df1_1.ix[df1_1['account type'].str.contains('mid', case=False).fillna(False),'account type'] = 'Named'\n",
    "    df1_1.ix[df1_1['account type'].str.contains('delet', case=False).fillna(False),'account type'] = 'Named'\n",
    "    write_wb(df1_1, df2_1, cols_rqrd1, cols_rqrd2, 2)\n",
    "\n",
    "def write_overlap_in_excel():\n",
    "    print 'Checking for overlapping....'\n",
    "    xl = pd.ExcelFile('../account_assignment/assignment_fy17_accounts_re_validated_v2.xlsx')\n",
    "    df = xl.parse('FY17 ACCOUNTS')\n",
    "    cols_rqrd = df.columns\n",
    "    cols_rqrd = cols_rqrd.append(pd.Series(['overlap_user_ids']))\n",
    "    df_full_dup_rem = df.drop_duplicates(['row'], keep=False)\n",
    "    df_half_dup_rem = df.drop_duplicates(['row'])\n",
    "    total = len(df.index)\n",
    "    no_dup_full = len(df_full_dup_rem.index)\n",
    "    no_dup_half = len(df_half_dup_rem.index)\n",
    "\n",
    "    df_full_dup = df[-df.row.isin(df_full_dup_rem.row)]\n",
    "    df_half_dup = df_full_dup.drop_duplicates(['row'], keep='first')\n",
    "    if len(df_full_dup.index) != 0:\n",
    "        df_half_dup.updated_file_name = df_half_dup['row'].map(lambda x: get_overlapped_file_names(x, df_full_dup))\n",
    "        df_half_dup['overlap_user_ids'] = df_half_dup['row'].map(lambda x: get_overlapped_user_ids(x, df_full_dup))\n",
    "\n",
    "        print \"Writing Overlapping data in Excel...\"\n",
    "        writer = pd.ExcelWriter('../account_assignment/assignment_overlapping.xlsx', engine='xlsxwriter')\n",
    "        df_full_dup.to_excel(writer, sheet_name='full_overlap', columns=df.columns)\n",
    "        df_half_dup.to_excel(writer, sheet_name='overlap', columns=cols_rqrd)\n",
    "        writer.save()\n",
    "        print \"Overlapping data has been written in Excel!\"\n",
    "    else:\n",
    "        print \"No Duplicates Found!\"\n",
    "    print \"Total Row(s): %d\" % (total)\n",
    "    print \"Non Duplicated Row(s): %d (ful) | %d (half)\" % (no_dup_full, no_dup_half)\n",
    "    print \"Remaining w.r.t Full Duplicates Row(s): %d\" % (len(df_full_dup.index))\n",
    "    print \"Remaining w.r.t Half Duplicates Row(s): %d\" % (len(df_half_dup.index))\n",
    "\n",
    "\n",
    "def check_changes():\n",
    "    xl = pd.ExcelFile('../account_assignment/FY17_WB_v1_mapped.xlsx')\n",
    "    df1 = xl.parse('FY17 ACCOUNTS')\n",
    "    df1.rename(columns=string.lower, inplace=True)\n",
    "    xl = pd.ExcelFile('../account_assignment/FY17_WB_v1_mapped_v2.xlsx')\n",
    "    df2 = xl.parse('FY17 ACCOUNTS')\n",
    "    df2.rename(columns=string.lower, inplace=True)\n",
    "    df_result = pd.merge(df2, df1, on='row')\n",
    "    return df_result\n",
    "\n",
    "#result = check_changes()\n",
    "#pd.set_option('display.max_rows', 180)\n",
    "#for x in result.columns:\n",
    "#    print x\n",
    "#result2 = result[pd.notnull(result['fy17 owner userid _x']) & ((result['fy17 owner userid _x'] != result['fy17 owner userid _y']) | (result['fy17 owner sl6 node_x'] != result['fy17 owner sl6 node_y']))]\n",
    "#result2 = result2[['row','fy17 owner userid _x','fy17 team agent name (for team agents only)_x','fy17 owner sl6 node_x','fy17 owner userid _y','fy17 team agent name (for team agents only)_y','fy17 owner sl6 node_y']]\n",
    "#writer = pd.ExcelWriter('../account_assignment/assignment_changes.xlsx', engine='xlsxwriter')\n",
    "#result2.to_excel(writer, sheet_name='change')\n",
    "#writer.save()\n",
    "#print len(result2.index)\n",
    "#validate_write_revision()\n",
    "#write_overlap_in_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49610\n",
      "Master File contains 49610 Row(s) | Update File contains 49610 Row(s)\n",
      "Split Dataframes (7644 + 41966) row(s) are EQUAL to Full DataFrame (49610) row(s)\n",
      "Split Dataframes (45519 + 4091) row(s) are EQUAL to Full DataFrame (49610) row(s)\n",
      "49610\n"
     ]
    }
   ],
   "source": [
    "def read_wb(file_name):\n",
    "    xl = pd.ExcelFile('../account_assignment/'+file_name+'.xlsx')\n",
    "    df = xl.parse('FY17 ACCOUNTS')\n",
    "    return df\n",
    "\n",
    "def check_split_counts(df):\n",
    "    df_blank = df[pd.isnull(df['FY17 Owner Userid '])]\n",
    "    df_nonblank = df[pd.notnull(df['FY17 Owner Userid '])]\n",
    "    full_len = len(df.index)\n",
    "    blank_len = len(df_blank.index)\n",
    "    nonblank_len = len(df_nonblank.index)\n",
    "    if (blank_len + nonblank_len) == full_len:\n",
    "        print \"Split Dataframes (%d + %d) row(s) are EQUAL to Full DataFrame (%d) row(s)\" % (blank_len, nonblank_len, full_len)\n",
    "    else:\n",
    "        print \"Split Dataframes (%d + %d) row(s) are NOT equal to Full DataFrame (%d) row(s)\" % (blank_len, nonblank_len, full_len)\n",
    "    return (df_blank, df_nonblank)\n",
    "    \n",
    "\n",
    "df_b = read_wb('FY17 Accounts WB_29th June_Bhavani')\n",
    "#df_s = read_wb('Shivani_WB_Enterprise_29th June')\n",
    "df_b['whose_file'] = 'bhavani'\n",
    "print len(df_b.drop_duplicates(['ROW']).index)\n",
    "#df_b.drop_duplicates(['ROW'], keep='last')\n",
    "df_s['whose_file'] = 'shivani'\n",
    "b_full_len = len(df_b.index)\n",
    "s_full_len = len(df_s.index)\n",
    "print \"Master File contains %d Row(s) | Update File contains %d Row(s)\" % (b_full_len, s_full_len)\n",
    "(df_b_blank, df_b_nonblank) = check_split_counts(df_b)\n",
    "(df_s_blank, df_s_nonblank) = check_split_counts(df_s)\n",
    "df_b_final = pd.concat([df_b_blank, df_s_nonblank])\n",
    "df_b_final = df_b_final.drop_duplicates(['ROW'], keep='last')\n",
    "df_b = pd.concat([df_b_nonblank, df_b_final])\n",
    "print len(df_b.drop_duplicates(['ROW'], keep='last').index)\n",
    "#print len(df_b.index)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROW\n",
      "Sales Level 2\n",
      "Sales Level 3\n",
      "Sales Level 4\n",
      "Sales Level 5\n",
      "Sales Level 6\n",
      "Segment\n",
      "Sub-Segment\n",
      "AM/Team Agent Name\n",
      "AM USERID\n",
      "SAV ID\n",
      "SAV Group Name\n",
      "Super Group Flag\n",
      "Party Id\n",
      "Party Name\n",
      "Party Type\n",
      "\n",
      "HQ Party ID\n",
      "Structured Account Template ID\n",
      "Structure Account Template Name\n",
      "\n",
      "Scope\n",
      "Split Percent\n",
      "DUNS no\n",
      "SFDC Account Owner Userid\n",
      "SFDC Account Name\n",
      "SFDC Account ID\n",
      "Line of Business\n",
      "Address Line 1\n",
      "City\n",
      "State/Province\n",
      "Country\n",
      "Total no of Employees\n",
      "No of PCs\n",
      "No of Phones\n",
      "FY16 Q4 Expected Product ($000)(Commit)\n",
      "FY16 Q4 Expected Product ($000) (Upside)\n",
      "FY16 Q4 Expected Service ($000) (Commit)\n",
      "FY16 Q4 Expected Service ($000) (Upside)\n",
      "FY17 Expected Product($000) (Commit)\n",
      "FY17 Expected Product($000) (Upside)\n",
      "FY14 Bookings (Product)\n",
      "FY14 Bookings (Service)\n",
      "FY15 Bookings (Product)\n",
      "FY15 Bookings (Service)\n",
      "FY16 M1-M10 Bookings (Product)\n",
      "FY16 M1-M10 Bookings (Service)\n",
      "Account Type\n",
      "FY17 Owner Userid \n",
      "FY17 Team Agent Name (for Team Agents only)\n",
      "FY17 OWNER SL6 NODE\n",
      "FY17 SAV GROUP NAME\n",
      "Sales Market Segment\n",
      "Sub Sales Market Segment\n",
      "Status\n",
      "Is_part_of_FY16_acc_move\n",
      "Mapped_Name\n",
      "Mapped_Node\n",
      "Unnamed: 56\n",
      "Refer\n",
      "commercial\n",
      "Unnamed: 59\n"
     ]
    }
   ],
   "source": [
    "for element in df_b.columns:\n",
    "    print element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
